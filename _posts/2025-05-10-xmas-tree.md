---
layout: post
title: IoT Christmas Tree
date: 2025-05-10 11:12:00-0400
description: Coordinate- and sensor-based Christmas tree lighting
tags: 
categories: 
thumbnail: assets/img/xmas-tree.jpg
related_posts: false
---

This project presents the development of an IoT-enabled Christmas tree featuring dynamic lighting and motion responsive to sensor data and user control. A Raspberry Pi manages a WS2811 RGB LED strip, BH1750 ambient light sensor, motion sensors, and servo-driven animatronic eyes with custom 3D-printed housing. Python libraries including rpi_ws281x and Flask were used for real-time LED control and web-based customization. A six-layer IoT model guided the system architecture, combining perception, data processing, actuation, networking, and user interfacing. 3D spatial mapping of the LEDs enabled complex, geometry-based animations, while real-time ambient brightness was visualized through a web dashboard. 

---

### Methods

Regarding setup and LED handling, a 2-foot Christmas tree was purchased along with a strip of 50 WS2811 programmable LEDs. Additionally, an independent 5 V power supply was purchased with a DC adapter that wires directly to the LED strip via WAGO connectors. The LEDs were positioned uniformly throughout the tree for the best visual experience; due to the circuitry of the LED strip, the LEDs light up in the order they are wired when they are sequentially programmed. To achieve a broader spectrum of animations (especially those based on geometry), 3D coordinates were collected for each LED. By using a 360-degree protractor and a tape measure, polar cooridnates were collected and then converted to Cartesian coordinates for use in generating complex light patterns. 

The I2C BH1750 light sensor was chosen to detect changes in ambient brightness in tandem with the lighting setup. Regardless of LED effects, this sensor dims or amplifies brightness based on ambient light. The ambient light (and subsequent LED brightness) is published on the user interface so that peak usage times can be estimated for a continuously lit tree and energy consumption can be decreased where appropriate. 

<div class="row mt-3">
  <div class="col-12">
    <div class="row justify-content-center">
      <div class="col-12 col-md-6">
        {% include figure.liquid
          loading="eager"
          path="assets/img/xmas-tree.jpg"
          class="img-fluid rounded z-depth-1"
        %}
      </div>
      <div class="col-12 col-md-6">
        {% include figure.liquid
          loading="eager"
          path="assets/img/bh1750.jpg"
          class="img-fluid rounded z-depth-1"
        %}
      </div>
    </div>
  </div>
</div>
<div class="caption">
    Once the tree was set up, polar coordinates were utilized to generate 50 3D coordinates (X,Y,Z) of each LED for geometry-based animations. The microcomputer also used ambient light readings delivered by the BH1750 sensor to control brightness of the LEDs.
</div>

---

### Results

For animating the lights, several mathematical- and time-based effects were brainstormed including fireworks, twisters, heartbeats, contagious (proximity-based) effects, and random planes or rotations. Music synchronization was also explored, but remains an item under further work as automating, synchronizing, and mapping music to LED effects requires advanced signal processing methods. The code can be found at [this GitHub repo](https://github.com/domsav13/iotxmastree). 

<div class="row mt-3 g-3 align-items-start">
  <!-- Video 1 -->
  <div class="col-12 col-md-4">
    <video
      autoplay
      loop
      muted
      playsinline
      preload="metadata"
      class="img-fluid rounded z-depth-1 w-100">
      <source src="{{ '/assets/img/contagious.mp4' | relative_url }}" type="video/mp4">
    </video>
  </div>

  <!-- Video 2 -->
  <div class="col-12 col-md-4">
    <video
      autoplay
      loop
      muted
      playsinline
      preload="metadata"
      class="img-fluid rounded z-depth-1 w-100">
      <source src="{{ '/assets/img/rainbow.mp4' | relative_url }}" type="video/mp4">
    </video>
  </div>

  <!-- Video 3 (manual play, not muted) -->
  <div class="col-12 col-md-4">
    <video
      controls
      playsinline
      preload="metadata"
      class="img-fluid rounded z-depth-1 w-100">
      <source src="{{ '/assets/img/mariah-carey.mp4' | relative_url }}" type="video/mp4">
    </video>
  </div>
</div>

<div class="caption">
  Simple light animations (proximity-based contagious and rainbow spiral effects). Mariah Carey's "All I Want for Christmas Is You" was also synchronized to the lights, although this was done manually instead of automated.
</div>

In Fall 2025, the project was expanded to a 500 LED, 7-foot Chrismas tree for the MAE department at GW. Instead of manually recording coordinates for each LED, the tree was modeled as a cone with an ascending helix representative of the LEDs spiraling throughout the tree. Using mathematical models of cones and spirals and taking basic measurements such as the upper and lower tree radii and number of turns, the 3D coordinates were parameterized for each LED index. 

<div class="row mt-3">
    <div class="col-12 col-md-6 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/500-leds.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Declining sensitivity in the COS NUV G225M grating. A similar trend is seen for G285M whereas the G185M and G230L gratings are not decreasing. This reduction in sensitivity results in lower signal-to-noise wavecal observations, which can cause CalCOS to return unreliable wavecal shifts. 
</div>

X

<div class="row mt-3 g-3 align-items-start">
  <!-- Video 1 -->
  <div class="col-12 col-md-4">
    <video
      autoplay
      loop
      muted
      playsinline
      preload="metadata"
      class="img-fluid rounded z-depth-1 w-100">
      <source src="{{ '/assets/img/500-contagious.mp4' | relative_url }}" type="video/mp4">
    </video>
  </div>

  <!-- Video 2 -->
  <div class="col-12 col-md-4">
    <video
      autoplay
      loop
      muted
      playsinline
      preload="metadata"
      class="img-fluid rounded z-depth-1 w-100">
      <source src="{{ '/assets/img/up-down.mp4' | relative_url }}" type="video/mp4">
    </video>
  </div>

  <!-- Video 3 (manual play, not muted) -->
  <div class="col-12 col-md-4">
    <video
      autoplay
      loop
      muted
      playsinline
      preload="metadata"
      class="img-fluid rounded z-depth-1 w-100">
      <source src="{{ '/assets/img/snakes.mp4' | relative_url }}" type="video/mp4">
    </video>
  </div>

<div class="caption">
  X
</div>



