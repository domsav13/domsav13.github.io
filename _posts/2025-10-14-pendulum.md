---
layout: post
title: Basic and Optimal Control of a Double Pendulum
date: 2025-10-14 11:12:00-0400
description: Control system design using pole placement, linear quadratic regulator, and Kalman filter
tags: 
categories: 
thumbnail: 
related_posts: false
---

### The Double Pendulum

The topic of study is the double pendulum system below, with angular states $\theta_1$, $\theta_2$, $\omega_1$, and $\omega_2$. The full system dynamics are modeled separately as Python simulator to be compared with the linearization derived below.

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/pendulum.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Double pendulum system used for this analysis.
</div>

The dynamics of the system can be described as

$$
M(\theta)\,\dot{\boldsymbol{\omega}} = \boldsymbol{f}(\theta,\boldsymbol{\omega})
$$

where

$$
M(\theta) =
\begin{bmatrix}
\frac{1}{3}m_1 l_1^2
+ m_2\!\left(l_1^2 + l_1 l_2 c_2 + \frac{1}{3}l_2^2\right)
&
m_2\!\left(\frac{1}{3}l_2^2 + \frac{1}{2}l_1 l_2 c_2\right)
\\[6pt]
m_2\!\left(\frac{1}{3}l_2^2 + \frac{1}{2}l_1 l_2 c_2\right)
&
\frac{1}{3}m_2 l_2^2
\end{bmatrix}
$$

$$
\boldsymbol{f}(\theta,\boldsymbol{\omega}) =
\begin{bmatrix}
m_2 l_1 l_2 s_2 \omega_1 \omega_2
+ \frac{1}{2}m_2 l_1 l_2 s_2 \omega_2^2
+ \left(\frac{1}{2}m_1 + m_2\right) g l_1 s_1
+ \frac{1}{2}m_2 g l_2 s_{12}
- \tau
\\[6pt]
\frac{1}{2}m_2 g l_2 s_{12}
- \frac{1}{2}m_2 l_1 l_2 s_2 \omega_1^2
+ \tau
\end{bmatrix}
$$

where $$ c_i = \cos(\theta_i) $$, $$ s_i = \sin(\theta_i) $$, and $$ s_{ij} = \sin(\theta_i + \theta_j) $$. An equilibrium is defined by $$ \dot{x} = 0 $$, where both angular velocities are zero and remain zero at that state. At the origin of this system, $$ c_1 = c_2 = \cos(0) = 1 $$ and $$ s_1=s_2=s_{12}=\sin(0)=0 $$. Assuming there is no external input, all terms in the rightmost matrix disappear, impling all states are zero. Hence when $$ (\theta_1, \theta_2, \omega_1, \omega_2) = (0,0,0,0) $$, and $$ \tau = 0 $$, $$ \dot{\theta}_1 = \dot{\theta}_2 = \dot{\omega}_1 = \dot{\omega}_2 = 0 $$ and therefore the origin of the state space is an equilibrium point.

To model the system around the origin, small-angle approximations $$ \sin(\theta_i) = \theta_i $$ and $$ \cos(\theta_i) = 1 $$ are used. The model parameters are taken as $$ m_1 = 0.5 $$ kg, $$ m_2 = 0.5 $$ kg, $$ l_1 = 1.0 $$ m, $$ l_2 = 1.0 m $$, and $$ g = 9.81 $$ m/s^2. Under these assumptions and parameters, the linearized system $$ \dot{x} = Ax+B\tau $$ is:

$$
\dot{x} = \begin{bmatrix}\dot{\theta}_1\\\dot{\theta}_2\\\dot{\omega}_1\\\dot{\omega}_2\end{bmatrix} = \begin{bmatrix}0&0&1&0\\0&0&0&1\\-12.61&12.61&0&0\\16.82&-46.25&0&0\end{bmatrix}x + \begin{bmatrix}0\\0\\-8.57\\27.43\end{bmatrix}\tau
$$

The eigenvalues of the state matrix $$ A $$ are $$ \pm 7.19i $$ and $$ \pm 2.68i $$. All eigenvalues are purely imaginary therefore the linearized system is Lyapunov stable (marginally stable) but not bounded-input bounded-output stable (asymptotically stable). 

---

### Controls

To determine controllability, the controllability matrix $$ C = \begin{bmatrix}B&AB&...&A^{n-1}B\end{bmatrix} $$ is computed:

$$
C = \begin{bmatrix}0&-8.57&0&454.06\\0&27.43&0&-1412.64\\-8.57&0&454.06&0\\27.43&0&-1412.64&0\end{bmatrix}
$$

The rank of $$ C $$ is 4, matching the dimension of state matrix $$ A $$, thus the system is controllable with the specified input.

---

#### Linear Dynamics

For this linearization, poles can be chosen using a controller of the form $u=-Kx$ to assign stable poles to the closed-loop state matrix $A-BK$. To test the performance of the controller, the following gains were computed using the place_poles function from scipy.signal to ensure stable poles:

$$
\begin{aligned}
K_1 &= \begin{bmatrix}-5.11 & -2.79 & 0.15 & 0.26\end{bmatrix} \\
\lambda(A-BK_1) &= [-2\pm 3i,\,-1\pm 2i] \\
\\
K_2 &= \begin{bmatrix}-5.49 & -1.60 & 8.27 & 2.95\end{bmatrix} \\
\lambda(A-BK_2) &= [-2\pm 3i,\,-3\pm 4i]
\end{aligned}
$$

Using these feedback gains, the state solutions and controll efforts are plotted below with initial conditions assigned as $$ x_0 = 0.01 $$. As expected, the controller takes less time to reach a steady state with decreasing negative real parts in the chosen poles. However, even though the system reaches a steady state faster at these gains, there is higher variance in the state behavior, especially as illustrated by $$ \omega_2 $$ for $$ K_2 $$ gains.

<div class="row mt-3 justify-content-center">
  <div class="col-12 col-md-8 text-center mb-3">
    {% include figure.liquid path="assets/img/linear-states-controller.jpg" class="img-fluid rounded z-depth-1" %}
  </div>

  <div class="col-12 col-md-8 text-center">
    {% include figure.liquid path="assets/img/linear-control-effort.jpg" class="img-fluid rounded z-depth-1" %}
  </div>
</div>
<div class="caption">
    States and controller performance for K_1 (left) and K_2 (right) feedback gains.
</div>

There are several limits for choosing pole locations for the double pendulum system. First, placing the poles too far left on the s-plane (large negative real parts) results in the feedback gain $$ K $$ growing significantly, meaning the controller may demand torques exceeding the actuator capabilities. 

---

#### Nonlinear Dynamics

To illustrate the differences due to the linear approximation and small-angle assumptions, the $$ K_1 $$ and $$ K_2 $$ control laws are applied to the nonlinear double pendulum plant simulator. 

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/nonlinear-pend-controllers.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    States simulated under the K_1 and K_2 control laws. Under both feedback gains, the states diverge around 2.5 seconds.
</div>

As observed, the state diverge as time increases and the control law with faster closed-loop poles results in much higher and less bounded state changes. When both angular states are near zero, the nonlinear dynamics match the linear model closely, resulting in a region where pole placements with negative real parts stabilize. However, as angles grow, the differences between the gains become more obvious. Faster poles result in larger gains which push the system outside of the linear region, and the controller, instead of balancing the dynamics, contributes to the divergence of the states.

---

#### Observation

For observability, we introduce $$ y = Cx $$ where the $$ C $$ matrix indicates sensors on certain states. Assuming a sensor that measures $$ \theta_2 $$, the $$ C $$ matrix becomes $$ \begin{bmatrix}0&1&0&0\end{bmatrix} $$. The observability matrix $$ O = \begin{bmatrix}C&CA&...&CA^{n-1}\end{bmatrix}^T $$ can be computed as:

$$
O = \begin{bmatrix}0&1&0&0\\0&0&0&1\\16.82&-46.25&0&0\\0&0&16.82&-46.25\end{bmatrix}
$$

The observability matrix has rank 4, matching the dimension of $$ A $$, which means the true state of the system with this sensor is observable.

---

#### Linear Dynamics

With the state observer, the goal is to design an estimator gain $$ L $$ such that the estimator error $$ \tilde{x} = x - \hat{x} $$ follows $$ \dot{\tilde{x}} = (A-LC)\tilde{x} $$. Choosing eigenvalues of $$ A - LC $$ to ensure pole placement in the left half of the s-plane makes the observer stable. As of now, the true state is used for feedback instead of the state estimator: $$ u = -Kx $$. In this analysis, the state observer poles are chosen by tripling the values used in $$ K_1 $$, ensuring faster poles than the controller. Under this setup, the state estimators quickly converge to the true states:

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/obs-fig1.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    True and estimated angular states, with a sensor on the second angle.
</div>

While it can be inferred above, below shows how the estimation error converges before the states reach zero. This is to be later compared with the outcome of the same setup using the nonlinear double pendulum simulator.

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/obs-fig2.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Convergence of the estimator and the true state.
</div>

---

#### Nonlinear Dynamics

For the nonlinear case, it is expected that the observer performs well for a short region of acceptance before the error diverges. Under the same setup, the estimator gain $$ L $$ is passed through the double pendulum simulator. 

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/obs-fig3.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    True and estimated angular states under nonlinear dynamics, with a sensor on the second angle. The estimate of the first angle quickly diverges from the true state.
</div>

As expected, by choosing faster poles, the observer gain $$ L $$ is very large and when the plant becomes nonlinear, the measurement $$ y = Cx $$ no longer corresponds to the true state, causing $$ \hat{x} $$ to overshoot and diverge. The error $$ x - \hat{x} $$ follows the same divergence pattern, which illustrates the major shortcomings of the linearization used in the initial problem setup.

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/obs-fig4.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Estimation error and true state divergence under the simulator's nonlinear dynamics.
</div>

---

### Linear Quadratic Regulator

A linear quadratic regulator (LQR) is an optimal control strategy for dynamic systems that minimizes a quadratic cost function to balance performance and control effort by calculating a gain the determines control input as a combination of the system's current state. In this design, a $$ Q $$ matrix is used to weigh states and a $$ R $$ matrix is used to weigh control effort. With a baseline design of $$ Q = R = I $$, the process to formulate the LQR gain $$ K $$ begins with solving for $$ P $$ in the continuous-time algebraic Riccati equation: $$ A^TP+PA-PBR^{-1}B^TP + Q = 0 $$. Then, the LQR gain matrix is computed as $$ K = R^{-1}B^TP $$. 

To evaluate LQR performance for a trajectory, the immediate loss $$ l(t) $$ and total loss $$ J(t) $$ are computed and plotted as:

$$
l(t)=x^TQx+u^TRu \quad\quad\quad J(t) = \int_0^t l(\tau)
$$

---

#### Linear Dynamics

First, the LQR gain is used on the linearized model of the double pendulum. The states start at small initial conditions and then begin to oscillate while remaining bounded. The oscillations are damped this way because the $$ Q = R = I $$ setup gives roughly equal weight to the states and input. The states do not diverge and the trajectory implies stability, boundedness, and effort minimization which are all expected otucomes of the LQR solution.

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/linearized-lqr-trajectories.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Closed-loop state trajectories and control input under LQR gain for the linearized double pendulum model. States become bounded and the input remains small.
</div>

To show optimality, the LQR gain is scaled to be higher for a comparison and the losses are assessed. For scale factor greater than one, the controller becomes more aggressive, applying stronger feedback than optimal. It is observed that after about 0.5 seconds, the loss representing higher gain sits slightly above the LQR loss, implying that the controller generates more control energy which has a higher cost at each instant. The conclusion is that the LQR solution achieves the same (or faster) convergence than nearby controllers with less total effort, proving optimality.

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/linearized-losses.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Instantaneous and cumulative quadratic loss for the LQR solution and a nearby controller, scaled to have a larger gain than the LQR.
</div>

To measure the impact of the $$ Q $$ and $$ R $$ matrices, three experiments are designed: one that heavily weights the positions, one that heavily weighs the velocities, and one that inflicts a higher cost on the control input. The angle-heavy design tries to correct angles faster, which results in slightly more aggressive changes in the state norm before settling close to the baseline whereas the velocity-heavy design instantly damps velocities hard, resulting in overshoot and slower decay. Lastly, only increasing the $$ R $$ matrix penalizes control effort, resulting in the smallest control signals and the slowest decay. 

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/linearized-states-varying-QR.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    LQR solutions for the linearized double pendulum system under varying Q and R designs.
</div>

These conclusions are reinforced by examining the input torque $$ u(t) $$ for each case. As expected, the largest $$ R $$ matrix uses the smallest torques. The velocity-heavy $$ Q $$ is less aggressive initially with the angle-heavy $$ Q $$ applying slightly stronger corrections. The baseline $$ Q = R = I $$ design sits between them, and the results illustrate the tradeoffs between state error and control energy.

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/linearized-inputs-varying-QR.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    LQR control efforts for the linearized double pendulum system under varying Q and R designs.
</div>

---

#### Nonlinear Dynamics

For each case, the LQR is implemented on the simulator and the state norms for each case are measured. Most notably, the velocity-heavy $$ Q $$ diverges fastest and is most unstable under the nonlinear dynamics because it does not adjust angular displacement well. The baseline and angle-heavy $$ Q $$ designs both grow but more moderately and remain somewhat bounded for small intervals of time. Lastly, the large $$ R $$ design produces gentle motion which keeps the pendulum in a more linear neighborhood and is effectively more stable than the other designs.

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/nonlinear-states-varying-QR.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    LQR solutions for the nonlinear simulation of the double pendulum system under varying Q and R designs.
</div>

The nonlinear control efforts are around an order of magnitude larger because the nonlinear dynamics at moderate angles are harder to combat. For the angle-heavy $$ Q $$, the control effort drops rapidly once angles are reduced, as expected. The velocity-heavy $$ Q $$ penalizes the angular velocities very strongly and the controller overreacts to small errors, resulting in large torque oscillations under the nonlinear dynamics. As before, the large $$ R $$ controller stays near the equilibrium region where the linear model is more valid.

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/nonlinear-inputs-varying-QR.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    LQR control efforts for the nonlinear simulation of the double pendulum system under varying Q and R designs.
</div>

---

### Kalman Filter

A Kalman filter estimates the state of a dynamic system by combining predictions with noisy measurements. It works by first estimating the state and its uncertainty followed by updating the estimate using a new measurement, giving more weight to the prediction or measurement based on their certainty. For systems with Gaussian noise, the Kalman filter provides the statistically optimal estimate of the system's state.

For the following analyses, a sensor is assigned to measure $$ \theta_2 $$, with $$ C = \begin{bmatrix}0&1&0&0\end{bmatrix} $$. 

---

#### Continuous Filter

For the continuous-time Kalman filter, the double pendulum system is modeled as

$$
\dot{x}=Ax+Bu+w \quad\quad\quad y=Cx+v
$$

where $$ w $$ and $$ v $$ represent the process and measurement noises, corresponding to the noise variance matrices $$ M = 0.01I $$ and $$ N = 0.1 $$, respectively. The observer estimates the state as:

$$
\dot{\hat{x}}=A\hat{x}+Bu+L(y-C\hat{x})
$$

where $$ \hat{x} $$ is the estimated state and $$ L $$ is the Kalman gain. By defining the estimation error as $$ e = x - \hat{x} $$, the error dynamics are characterized by:

$$
\dot{e} = (A-LC)e+w-Lv
$$

The observer dynamics are governed by $$ A-LC $$ and thus the observer is stable if all eigenvalues of $$ A-LC $$ have negative real parts. To minimize the steady-state estimation error covariance $$ P = \mathbb{E}[ee^T] $$, $$ P $$ is solved from the continuous-time algebraic Riccati equation $$ AP+PA^T-PC^TN^{-1}CP+M=0 $$. Then, the Kalman gain is given by $$ L = PC^TN^{-1} $$. 

Below, the true angles $$ \theta_1 $$ and $$ \theta_2 $$ are presented with their estimates, showing smooth and stable convergence. For this experiment, the assumed noise covariances match model reality, and the Kalman gain $$ L $$ gives an optimal balance between model prediction and sensor correction. The estimates follow the true trajectories with some lag and reduced amplitude which are typical of a Kalman filter when the assumed covariances match. The eigenvalues of $$ A - LC $$ all have negative real parts, confirming a stable observer, which is further conveyed by the boundedness of the error $$ x - \hat{x} $$. 

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/continuous-kf-matched.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Continuous-time Kalman filter on angular states for the matched noise case.
</div>

The next figure presents the mismatched noise case where the filter assumes incorrect covariances when solving for $$ L $$, with $$ M_{new} = 100M $$ and $$ N_{new} = 0.01N $$. In this case, the filter believes the model is much noisier and the sensor is much more accurate than it really is. As a result, the estimates react strongly to measurement variations, producing visibly higher-frequency fluctuations. Compared to the matched noise case, the mismatched design trades off noise rejection for responsiveness. 

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/continuous-kf-mismatched.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Continuous-time Kalman filter on angular states for the mismatched noise case.
</div>

---

#### Discrete Filter

For the discrete model, the state space is given by:

$$
x_{k+1}=Ax_k+Bu_k+w_k \quad\quad\quad y_k=Cx_k+v_k
$$

with the same Gaussian noise setup as before. For the prediction step, the filter predicts the next state and covariance based on prior estimates

$$
\hat{x}_{k|k-1}=A\hat{x}_{k-1|k-1}+Bu_{k-1} \quad\quad\quad P_{k|k-1}=AP_{k-1|k-1}A^T+M
$$

and once a measurement $$ y_k $$ arrives, the prediction is corrected in the update stage and the discrete Kalman gain $$ K_k $$ is computed:

$$
\begin{aligned}
K_k &= P_{k|k-1}C^T\left(CP_{k|k-1}C^T+N\right)^{-1} \\
\hat{x}_{k|k} &= \hat{x}_{k|k-1}+K_k\left(y_k-C\hat{x}_{k|k-1}\right) \\
P_{k|k} &= \left(I-K_kC\right)P_{k|k-1}
\end{aligned}
$$

where $P_{k|k}$ is the updated error covariance and $P_{k|k-1}$ is the predicted error covariance. At steady state, $K_k$ and $P_k$ converge to constant values where $P$ solves the discrete-time algebraic Riccati equation
$$
P = APA^T+M-APC^T\left(CPC^T+N\right)^{-1}CPA^T
$$. 
Then, the Kalman gain is computed as
$$
K = PC^T\left(CPC^T+N\right)^{-1}
$$.

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/discrete-kf.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Discrete Kalman filter on the angular states for the matched noise case. The convergence of the covariance is also shown.
</div>

As seen above, the estimates closely track the true angles but appear somewhat noisy, due to the measurement noise $$ v_k $$ being incorporated during each update. Both estimates remain bounded and follow the correct trends, showing that the filter is stable and performing proper sensor fusion. In the subplot, the trace of $$ P_k $$ measures the total uncertainty in the state estimate and settles to a steady-state value, implying the convergence of the discrete-time Riccati equation.

---

#### Nonlinear Filter

To generalize the discrete Kalman filter to the nonlinear dynamics, an extended Kalman filter (EKF) is designed as follows:

$$
x_{k+1}=f(x_k,u_k)+w_k \quad\quad\quad y_k=h(x_k)+v_k
$$

where $f$ and $h$ are nonlinear functions. The nonlinear dynamics are approximated by their first-order Taylor expansion, producing local Jacobians that replace the fixed $A$ and $C$ matrices of the linear filter:

$$
F_k = \left.\frac{\partial f}{\partial x}\right|_{\hat{x}_k,u_k}
\qquad\qquad
H_k = \left.\frac{\partial h}{\partial x}\right|_{\hat{x}_{k+1|k}}
$$

As illustrated below, the EKF simulation demonstrates stable and accurate estimation fot eh nonlinear dynamics when the system remains close to the linearization point. The estimator successfully reconstructs both measured and unmeasured angles with bounded estimation error and a decreasing covariance trace, however performance degrades as the system departs from the validity of the local Jacobians.

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/ekf.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Extended Kalman filter on the nonlinear plant. The EKF estimates generally track the true angles, but error rises as the local Jacobian becomes less accurate. For small nonlinear motion near the equilibrium, the EKF (which relinearizes each step) provides slightly better estimates than a fixed-model linear Kalman filter.
</div>

---

#### Estimated State Feedback

This section demonstrates how the LQR feedback loop and the Kalman filter estimation loop interact when the filters are supplying feedback. The figure below describes how the estimated state feedback behaves when the relative speeds of the controller (LQR gain $$ K $$) and the state estimator (Kalman filter gain $$ L $$) are scaled:

$$
K_c = \alpha K \quad\quad\quad L_c = \beta L
$$

where $$ \alpha $$ controls how aggressively the controller responds and $$ \beta $$ controls how aggressively the Kalman filter trusts measurements.

<div class="row mt-3">
    <div class="col-12 col-md-7 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/lqg-scaled.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Scaling effects of controller and estimator gains on the linearized and nonlinear models for state changes of the second angle. The performance cost measuring estimation quality and control effort is also computed and shown for each simulation.
</div>

In the first scenario, the controller reacts slowly and the filter reacts aggressively, resulting in an estimator that tracks well but with small control in the linear model. In the nonlinear case, however, the filter overreacts to noisy measurement and the controller thus acts on inaccurate estimates. For the opposite case, with an aggressive controller and slow filter, the linear system rapidly stabilizes. In the nonlinear case, the controller reacts much faster than the EKF can estimate, so inputs are based on distorted estimates, leading to instability and very high cost. When the subsystems are scaled in tandem, the linear model produces a smooth, well-damped response with moderate inputs. Most notably, the EKF for the nonlinear model estimates states accurately enough to maintain reasonable feedback. The controller and observer operate on compatible time scales, resulting in the best performing configuration for the nonlinear system.
