---
layout: post
title: Object tracking and identification
date: 2025-03-10 11:12:00-0400
description: Pocket-sized computer vision (OpenCV)
tags: 
categories: 
thumbnail: assets/img/opencv.jpg
related_posts: false
---

This project explores computer vision-based object detection and facial recognition using a Raspberry Pi 4B and PiCamera V2.1 to create a compact, real-time security/detection system. The detection model captures video frames, processes them in real time, and sends notifications when a target is detected. OpenCV, a widely used computer vision library, and the COCO dataset were used to develop and train the model. The object detection performed reliably with adjustable confidence thresholds, but facial recognition struggled with prolonged use due to hardware limitations.

---

### Background

Using a three-layer IoT model incorporating the perception, network, and application layers, the final product seeks to generate email notifications based on visual detection methods. The work si inspired by security and privacy computer vision-based systems (Ring, Apple Face ID, etc.). 

OpenCV is a free computer vision and machine learning library built to advance machine perception in commercial products, featuring thousands of optimized algorithms that can be used to detect and recognize faces, identify objects, classify gestures, and more. The fundamentals of object detection in OpenCV involve two main tasks: classification and localization. Most methods work to determine the exact location of an object within an image or video feed by using bounding boxes or segmentation. The promises of OpenCV rely fully on the models that are provided, which is why the Common Objects in Context (COCO) dataset is essential for the success of project goals.

COCO is a large-scale object detection dataset that features recognition of over 200,000 labeled images among 1.5 million object instances. The datasets are open source and are available for download, and are designed to train and evaluate detection models with rich contextual data and precise localization via "segmentation masks," a specific portion of an image that is isolated from the rest. This project will use OpenCV algorithms to train these labeled images so that a Raspberry Pi and PiCamera can detect objects and alert the user in real time.

---

### Methods and implementation

The requirements ofr this project include a Raspberry Pi 4 (flashed with the Buster version of the Debian OS) and PiCamera V2.1. The camera interfaces with the microcomputer with a ribbon connector.

<div class="row mt-3">
    <div class="col-12 col-md-5 mx-auto mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/eyepi-workflow.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    Software workflow for the email notification and object detection system.
</div>

The primary goal of the code is to detect a specific object, capture an image when the object is detected, and send an email with the image attached. The pre-trained COCO dataset incorporates the labeling of 91 common everyday objects. The object detection model is configured using these COCO files to define class labels and specify weights, which is later loaded by the OpenCV deep neural network module. A video capture continuously reads frames and passes thrm through a function that checks whether the detected object matches the target object specified by the user. If so, it draws a bounding box and a label around the object on the image, saves it, and sends it via email. This function is central to the object detection process, as it uses a confidence and non-maximum suppression (NMS) threshold. The confidence threshold filters out low-confidence detections and the NMS thresholds reduces overlapping boxes to avoid dupplicate detections. The email is sent using SMTP, EmailMessage, and a Gmail account with app passwords enabled to include a subject and body message indicating that the object was detected, attaching the saved image as well.

All code is presented at [this GitHub repo](https://github.com/domsav13/eyepi).

---

### Results

Overall, the methods satisfied basic requirements but were limited due to hardware constraints. The limited computing power of the Raspberry Pi and low frame rates in the video feed limited the performance of the software, however the object detection model met expectations.

<div class="row mt-3">
  <div class="col-12">
    <div class="row justify-content-center">
      <div class="col-12 col-md-6">
        {% include figure.liquid
          loading="eager"
          path="assets/img/detection-left.jpg"
          class="img-fluid rounded z-depth-1"
        %}
      </div>
      <div class="col-12 col-md-6">
        {% include figure.liquid
          loading="eager"
          path="assets/img/detection-right.jpg"
          class="img-fluid rounded z-depth-1"
        %}
      </div>
    </div>
  </div>
</div>
<div class="caption">
    Exclusive search within the video feed, filtering out specified objects. Bounding boxes and confidence levels are shown around each object.
</div>

